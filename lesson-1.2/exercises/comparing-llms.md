# Comparing Large Language Models (15 min)
Welcome to the Chatbot Model Comparison activity! Here, you will compare the output of three different chatbot models. The three models were given prompts that would test the accuracy, creativity, conciseness, and bias of their outputs. Your job is to select the model that performed best in each category. Let's get started!

Complete the activity [here](https://igfnaqfcyl-13589482-i.codehs.me/index.html).  Then edit this page and write down your reflections here:

### Which model did you find performed best overall, and why?
The best overall was model B because it answered everything well and it was short and simple. It gave just enough information to answer the questions and nothing more.

### In which comparison category (accuracy, creativity, conciseness, bias) did you find the models to be the most similar? What about the most different?
Conciseness was the most similar because they both did exactly what was told and give one pro and one con. Creativity was most different because all of their words and examples were different from each other.

### Were you surprised by any of the results?
I was surprised about how much Llama 3 wrote. The other two models had relatively short answers but Llama 3 wrote a lot more and added things that weren't even asked for.

### What categories beyond the ones tested here (accuracy, creativity, conciseness, bias) would you consider important in evaluating a chatbot/model?
Advice because a lot of people ask chatbots what they should do so it would be interesting to see how they think when it comes to that and which gives the best advice.
